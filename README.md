# ğŸ” [Quantization in Depth](https://www.deeplearning.ai/short-courses/quantization-in-depth/)

ğŸ’¡ Welcome to the "Quantization in Depth" course! This course delves into advanced quantization techniques to compress and optimize models, making them more accessible and efficient.

## Course Summary
In this course, you'll explore in-depth quantization methods to reduce model weights and maintain performance. Here's what you can expect to learn and experience:

1. âš™ï¸ **Linear Quantization**: Build and customize linear quantization functions, exploring modes (asymmetric and symmetric) and granularities (per-tensor, per-channel, and per-group).
2. ğŸ“ **Quantization Error Measurement**: Measure the quantization error of different options, balancing performance and space trade-offs.
3. ğŸ› ï¸ **PyTorch Quantizer**: Implement a general-purpose quantizer in PyTorch to compress model weights from 32 bits to 8 bits.
4. ğŸ§© **Advanced Techniques**: Pack four 2-bit weights into one 8-bit integer, going beyond standard 8-bit quantization.

## Key Points
- ğŸ”„ Explore different variants of Linear Quantization, including symmetric vs. asymmetric modes and various granularities.
- ğŸ§  Build a general-purpose quantizer in PyTorch for up to 4x compression on dense layers of any open-source model.
- ğŸ“¦ Implement weight packing to compress four 2-bit weights into a single 8-bit integer.

## About the Instructors
ğŸŒŸ **Marc Sun** and **Younes Belkada** are Machine Learning Engineers at Hugging Face, bringing extensive expertise in model compression and optimization to guide you through this advanced course.

ğŸ”— To enroll in the course or for further information, visit [deeplearning.ai](https://www.deeplearning.ai/short-courses/).
